{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0688472",
   "metadata": {},
   "source": [
    "# ======================================\n",
    "# NLP Model Training for SATIM FAQ Bot\n",
    "# ======================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b06147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Morsi Store\n",
      "[nltk_data]     DZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import dependencies\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', force=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "print(\"Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcbdde",
   "metadata": {},
   "source": [
    "\n",
    "# ======================================\n",
    "# 1. Load Scraped Data\n",
    "# ======================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a9749b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 FAQs\n",
      "Categories: ['Contact', 'Informations', 'Paiements', 'Support']\n",
      "\n",
      "Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   question         4 non-null      object\n",
      " 1   answer           4 non-null      object\n",
      " 2   category         4 non-null      object\n",
      " 3   source_url       4 non-null      object\n",
      " 4   question_length  4 non-null      int64 \n",
      " 5   answer_length    4 non-null      int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 324.0+ bytes\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "                                            question  \\\n",
      "0  Comment puis-je contacter le service client SA...   \n",
      "1      Quels sont les horaires d'ouverture de SATIM?   \n",
      "2   Comment puis-je effectuer un paiement via SATIM?   \n",
      "3            Que faire en cas de probl√®me technique?   \n",
      "\n",
      "                                              answer      category  \\\n",
      "0  Vous pouvez contacter le service client SATIM ...       Contact   \n",
      "1  SATIM est g√©n√©ralement ouvert du dimanche au j...  Informations   \n",
      "2  SATIM propose plusieurs m√©thodes de paiement √©...     Paiements   \n",
      "3  En cas de probl√®me technique, contactez imm√©di...       Support   \n",
      "\n",
      "                     source_url  question_length  answer_length  \n",
      "0  https://www.satim.dz/default               50            149  \n",
      "1  https://www.satim.dz/default               45            115  \n",
      "2  https://www.satim.dz/default               48            135  \n",
      "3  https://www.satim.dz/default               39            132  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../data/processed/satim_faqs_cleaned.csv')\n",
    "\n",
    "print(f\"Loaded {len(df)} FAQs\")\n",
    "print(f\"Categories: {list(df['category'].unique())}\")\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a7770",
   "metadata": {},
   "source": [
    "\n",
    "# ======================================\n",
    "# 2. Text Preprocessing\n",
    "# ======================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load French model\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "\n",
    "# Optional: Your stopwords if you have a custom list\n",
    "french_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "def preprocess_french_text(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Lowercase and basic cleaning\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s\\-√†√¢√§√ß√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ø]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # spaCy processing\n",
    "    doc = nlp(text)\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc\n",
    "        if token.text not in french_stopwords and not token.is_punct and len(token.text) > 2\n",
    "    ]\n",
    "\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0f185fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Comment puis-je contacter le service client de SATIM pour r√©soudre mon probl√®me?\n",
      "Processed: je contacter service client satim r√©soudre probl√®me\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Comment puis-je contacter le service client de SATIM pour r√©soudre mon probl√®me?\"\n",
    "processed_text = preprocess_french_text(sample_text)\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Processed: {processed_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a627c",
   "metadata": {},
   "source": [
    "\n",
    "# ======================================\n",
    "# 3. Prepare Training Data\n",
    "# ======================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0691e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text data...\n",
      "After preprocessing: 4 FAQs\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing text data...\")\n",
    "df['processed_question'] = df['question'].apply(preprocess_french_text)\n",
    "df['processed_answer'] = df['answer'].apply(preprocess_french_text)\n",
    "df = df[(df['processed_question'].str.len() > 0) & (df['processed_answer'].str.len() > 0)]\n",
    "print(f\"After preprocessing: {len(df)} FAQs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ca2965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 1 ---\n",
      "Original Q: Comment puis-je contacter le service client SATIM?\n",
      "Processed Q: je contacter service client satim\n",
      "\n",
      "--- Example 2 ---\n",
      "Original Q: Quels sont les horaires d'ouverture de SATIM?\n",
      "Processed Q: horaire ouverture satim\n",
      "\n",
      "--- Example 3 ---\n",
      "Original Q: Comment puis-je effectuer un paiement via SATIM?\n",
      "Processed Q: je effectuer paiement satim\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(f\"Original Q: {df.iloc[i]['question']}\")\n",
    "    print(f\"Processed Q: {df.iloc[i]['processed_question']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001075e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ======================================\n",
    "# 4. TF-IDF Vectorizer\n",
    "# ======================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e03dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (4, 2)\n",
      "Vocabulary size: 2\n",
      "Sample features: ['je' 'satim']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "question_vectors = vectorizer.fit_transform(df['processed_question'])\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {question_vectors.shape}\")\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "print(f\"Sample features: {vectorizer.get_feature_names_out()[:20]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b2b5ab",
   "metadata": {},
   "source": [
    "\n",
    "# ======================================\n",
    "# 5. FAQ Similarity Model\n",
    "# ======================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e745f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAQSimilarityModel:\n",
    "    def __init__(self, vectorizer, question_vectors, faq_data):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.question_vectors = question_vectors\n",
    "        self.faq_data = faq_data.reset_index(drop=True)\n",
    "\n",
    "    def find_best_match(self, query, top_k=3, min_similarity=0.1):\n",
    "        processed_query = preprocess_french_text(query)\n",
    "        if not processed_query:\n",
    "            return []\n",
    "        query_vector = self.vectorizer.transform([processed_query])\n",
    "        similarities = cosine_similarity(query_vector, self.question_vectors).flatten()\n",
    "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            similarity = similarities[idx]\n",
    "            if similarity >= min_similarity:\n",
    "                results.append({\n",
    "                    'question': self.faq_data.iloc[idx]['question'],\n",
    "                    'answer': self.faq_data.iloc[idx]['answer'],\n",
    "                    'category': self.faq_data.iloc[idx]['category'],\n",
    "                    'similarity': float(similarity),\n",
    "                    'confidence': self.calculate_confidence(similarity)\n",
    "                })\n",
    "        return results\n",
    "\n",
    "    def calculate_confidence(self, similarity):\n",
    "        if similarity >= 0.8:\n",
    "            return 'high'\n",
    "        elif similarity >= 0.5:\n",
    "            return 'medium'\n",
    "        elif similarity >= 0.2:\n",
    "            return 'low'\n",
    "        else:\n",
    "            return 'very_low'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5fe23d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì FAQ Similarity Model created successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "faq_model = FAQSimilarityModel(vectorizer, question_vectors, df)\n",
    "print(\"‚úì FAQ Similarity Model created successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde6474d",
   "metadata": {},
   "source": [
    "\n",
    "# ======================================\n",
    "# 6. Test Model\n",
    "# ======================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93c7a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_queries = [\n",
    "    \"Comment contacter SATIM?\",\n",
    "    \"Quels sont vos horaires d'ouverture?\",\n",
    "    \"Comment faire un paiement?\",\n",
    "    \"J'ai un probl√®me technique\",\n",
    "    \"O√π √™tes-vous situ√©s?\",\n",
    "    \"Comment cr√©er un compte?\",\n",
    "    \"Probl√®me avec ma carte\",\n",
    "    \"Tarifs et frais\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74c02f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "üîç Test Query 1: 'Comment contacter SATIM?'\n",
      "--------------------------------------------------\n",
      "\n",
      "  Match 1 (Similarity: 1.000, Confidence: high)\n",
      "  Q: Quels sont les horaires d'ouverture de SATIM?\n",
      "  A: SATIM est g√©n√©ralement ouvert du dimanche au jeudi de 8h00 √† 17h00. Les horaires peuvent varier selon les services....\n",
      "  Category: Informations\n",
      "\n",
      "  Match 2 (Similarity: 0.629, Confidence: medium)\n",
      "  Q: Comment puis-je effectuer un paiement via SATIM?\n",
      "  A: SATIM propose plusieurs m√©thodes de paiement √©lectronique. Contactez-nous pour conna√Ætre les options disponibles selon votre situation....\n",
      "  Category: Paiements\n",
      "\n",
      "üîç Test Query 2: 'Quels sont vos horaires d'ouverture?'\n",
      "--------------------------------------------------\n",
      "  ‚ùå No suitable matches found\n",
      "\n",
      "üîç Test Query 3: 'Comment faire un paiement?'\n",
      "--------------------------------------------------\n",
      "  ‚ùå No suitable matches found\n",
      "\n",
      "üîç Test Query 4: 'J'ai un probl√®me technique'\n",
      "--------------------------------------------------\n",
      "  ‚ùå No suitable matches found\n",
      "\n",
      "üîç Test Query 5: 'O√π √™tes-vous situ√©s?'\n",
      "--------------------------------------------------\n",
      "  ‚ùå No suitable matches found\n",
      "\n",
      "üîç Test Query 6: 'Comment cr√©er un compte?'\n",
      "--------------------------------------------------\n",
      "  ‚ùå No suitable matches found\n",
      "\n",
      "üîç Test Query 7: 'Probl√®me avec ma carte'\n",
      "--------------------------------------------------\n",
      "  ‚ùå No suitable matches found\n",
      "\n",
      "üîç Test Query 8: 'Tarifs et frais'\n",
      "--------------------------------------------------\n",
      "  ‚ùå No suitable matches found\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\nüîç Test Query {i}: '{query}'\")\n",
    "    print(\"-\" * 50)\n",
    "    results = faq_model.find_best_match(query, top_k=2)\n",
    "    if results:\n",
    "        for j, result in enumerate(results, 1):\n",
    "            print(f\"\\n  Match {j} (Similarity: {result['similarity']:.3f}, Confidence: {result['confidence']})\")\n",
    "            print(f\"  Q: {result['question']}\")\n",
    "            print(f\"  A: {result['answer'][:150]}...\")\n",
    "            print(f\"  Category: {result['category']}\")\n",
    "    else:\n",
    "        print(\"  ‚ùå No suitable matches found\")\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1881f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_questions = df['question'].tolist()  # or use df['processed_question'] if you want cleaned version\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8a97555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Matches:\n",
      "----------------------------------------\n",
      "Score: 0.854\n",
      "Q: Comment puis-je effectuer un paiement via SATIM?\n",
      "A: SATIM propose plusieurs m√©thodes de paiement √©lectronique. Contactez-nous pour conna√Ætre les options disponibles selon votre situation....\n",
      "Category: Paiements\n",
      "----------------------------------------\n",
      "Score: 0.209\n",
      "Q: Comment puis-je contacter le service client SATIM?\n",
      "A: Vous pouvez contacter le service client SATIM par t√©l√©phone, email ou en visitant nos bureaux. Consultez notre page contact pour plus d'informations....\n",
      "Category: Contact\n",
      "----------------------------------------\n",
      "Score: 0.169\n",
      "Q: Que faire en cas de probl√®me technique?\n",
      "A: En cas de probl√®me technique, contactez imm√©diatement notre support technique. Nous vous aiderons √† r√©soudre le probl√®me rapidement....\n",
      "Category: Support\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch  # ‚úÖ This is the missing import\n",
    "\n",
    "# Load multilingual model\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Define list of questions\n",
    "list_of_questions = df['question'].tolist()  # or use df['processed_question'].tolist() for cleaned\n",
    "\n",
    "# Encode all FAQ questions\n",
    "corpus_embeddings = model.encode(list_of_questions, convert_to_tensor=True)\n",
    "\n",
    "# Encode the user query\n",
    "query = \"Comment faire un paiement?\"\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)\n",
    "\n",
    "# Top-k results\n",
    "top_k = 3\n",
    "top_results = torch.topk(cosine_scores, k=top_k)\n",
    "\n",
    "# Print matches\n",
    "print(\"\\nTop Matches:\\n\" + \"-\" * 40)\n",
    "for score, idx in zip(top_results[0][0], top_results[1][0]):\n",
    "    index = idx.item()  # convert tensor to int\n",
    "    print(f\"Score: {score.item():.3f}\")\n",
    "    print(f\"Q: {df.iloc[index]['question']}\")\n",
    "    print(f\"A: {df.iloc[index]['answer'][:150]}...\")\n",
    "    print(f\"Category: {df.iloc[index]['category']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14adc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"Comment faire un paiement?\", \"Paiement avec SATIM\", \"M√©thodes de paiement disponibles\"]\n",
    "# Encode all, average embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04716ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, df, model, top_k=3, threshold=0.5):\n",
    "    questions = df['processed_question'].tolist()\n",
    "    corpus_embeddings = model.encode(questions, convert_to_tensor=True)\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)\n",
    "    top_results = torch.topk(cosine_scores, k=top_k)\n",
    "    \n",
    "    print(\"\\nTop Matches:\\n\" + \"-\" * 40)\n",
    "    for score, idx in zip(top_results[0][0], top_results[1][0]):\n",
    "        score_val = score.item()\n",
    "        if score_val < threshold:\n",
    "            continue\n",
    "        index = idx.item()\n",
    "        print(f\"Score: {score_val:.3f}\")\n",
    "        print(f\"Q: {df.iloc[index]['question']}\")\n",
    "        print(f\"A: {df.iloc[index]['answer'][:150]}...\")\n",
    "        print(f\"Category: {df.iloc[index]['category']}\")\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8edddf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Matches:\n",
      "----------------------------------------\n",
      "Score: 0.736\n",
      "Q: Comment puis-je effectuer un paiement via SATIM?\n",
      "A: SATIM propose plusieurs m√©thodes de paiement √©lectronique. Contactez-nous pour conna√Ætre les options disponibles selon votre situation....\n",
      "Category: Paiements\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the function with a test query\n",
    "test_query = \"Comment faire un paiement?\"\n",
    "results = semantic_search(test_query, df, model)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495f388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv SATIM)",
   "language": "python",
   "name": "callcenter-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
